{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8754fc76-dcd2-453b-9693-3ec9336cc548",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this exercise, we will learn:\n",
    "    \n",
    "    1. How to perform multi-class classification with a deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8acd4e0-82d3-4e75-8f94-d4184e794d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# glob is used for manipulating files\n",
    "import pandas as pd\n",
    "import glob\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525eee8d-2bb3-4b8e-aaf2-03226387ed79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found: \n",
      "['\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\0.csv', '\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\1.csv', '\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\2.csv', '\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\3.csv', '\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\4.csv', '\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\5.csv', '\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\6.csv', '\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\7.csv']\n",
      "             Timestamp  Sensor1  Sensor2  label\n",
      "0  2025-03-13 17:13:19      384      200      0\n",
      "1  2025-03-13 17:13:19      381      194      0\n",
      "2  2025-03-13 17:13:19      377      197      0\n",
      "3  2025-03-13 17:13:20      382      197      0\n",
      "4  2025-03-13 17:13:20      375      194      0\n"
     ]
    }
   ],
   "source": [
    "# Finding all .csv files in the directory of this python script\n",
    "files = glob.glob(\"\\\\Users\\\\Mattia\\\\Desktop\\\\Smart Werables\\\\Project\\\\data_collection\\\\Pietro\\\\*.csv\")\n",
    "\n",
    "print(\"Files found: \")\n",
    "print(files)\n",
    "\n",
    "dataframes = []\n",
    "# Caricamento del file CSV\n",
    "for file in files:\n",
    "    df = pd.read_csv(file) \n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenazione di tutti i DataFrame in uno solo\n",
    "df_final = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Visualizzazione delle prime righe per verifica\n",
    "print(df_final.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22779a8e-fda1-480c-9b4f-16744e4f4322",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di classi: 8\n",
      "Numero di canali (sensori): 2\n",
      "Numero di finestre per classe: [10, 3, 4, 11, 11, 11, 13, 5]\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of classes (the number of classes is the number of files since we assume each file is for a different class)\n",
    "# Numero di classi (etichettato nei file)\n",
    "num_classes = df_final[\"label\"].nunique()  # Conta le classi uniche\n",
    "num_channels = df_final.shape[1] - 2  # Escludiamo timestamp e label\n",
    "\n",
    "# Loading all the files into a list\n",
    "data_per_class        = []\n",
    "num_samples_per_class = []\n",
    "num_windows_per_class = []\n",
    "\n",
    "# Defining window length and step size\n",
    "window_length     = 50\n",
    "window_step_size  = 25\n",
    "\n",
    "# Loading the files and finding the number of samples and windows for each class\n",
    "for label in range(num_classes):\n",
    "    #data = np.loadtxt(file, delimiter=\",\",  usecols=range(1, num_channels + 1))\n",
    "    #data = np.loadtxt(file, delimiter=\",\", skiprows=1, usecols=range(1, num_channels + 1))\n",
    "    # data = np.loadtxt(file, delimiter=\",\")\n",
    "    # Selezioniamo solo i dati della classe corrente\n",
    "    data = df_final[df_final[\"label\"] == label].iloc[:, 1:-1].values  # Escludiamo timestamp e label\n",
    "    data_per_class.append(data) \n",
    "    num_samples = data.shape[0]\n",
    "    num_samples_per_class.append(num_samples)\n",
    "    num_windows = (num_samples - window_length) // window_step_size + 1\n",
    "    num_windows_per_class.append(num_windows)\n",
    "print(f\"Numero di classi: {num_classes}\")\n",
    "print(f\"Numero di canali (sensori): {num_channels}\")\n",
    "print(f\"Numero di finestre per classe: {num_windows_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a164a885-0f75-47f3-8f6a-b1b04cf2d12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finestre generate per classe: [10]\n",
      "Finestre generate per classe: [10, 3]\n",
      "Finestre generate per classe: [10, 3, 4]\n",
      "Finestre generate per classe: [10, 3, 4, 11]\n",
      "Finestre generate per classe: [10, 3, 4, 11, 11]\n",
      "Finestre generate per classe: [10, 3, 4, 11, 11, 11]\n",
      "Finestre generate per classe: [10, 3, 4, 11, 11, 11, 13]\n",
      "Finestre generate per classe: [10, 3, 4, 11, 11, 11, 13, 5]\n"
     ]
    }
   ],
   "source": [
    "sliding_windows_per_class = []\n",
    "\n",
    "# Creating the sliding windows\n",
    "for class_id in range(0, num_classes):\n",
    "    num_windows = num_windows_per_class[class_id]\n",
    "    sliding_windows = np.zeros((num_windows, window_length, num_channels))\n",
    "    for i in range(0, num_windows):\n",
    "        sliding_windows[i, ...] = data_per_class[class_id][i*window_step_size: i*window_step_size + window_length]\n",
    "    sliding_windows_per_class.append(sliding_windows)\n",
    "    print(f\"Finestre generate per classe: {[len(w) for w in sliding_windows_per_class]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece4f019-7540-4b0a-adcc-295a94f9b52b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remember that we don't need to extract features. \n",
    "\n",
    "# We now split the data into train, val and test sets\n",
    "train_portion = 0.70\n",
    "val_portion   = 0.15\n",
    "\n",
    "num_windows_all_classes = np.sum(num_windows_per_class)\n",
    "\n",
    "# Creating lists that will store the train, val and test portions of all classes\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_val = []\n",
    "Y_val = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for class_id in range(0, num_classes):\n",
    "    num_windows = num_windows_per_class[class_id]\n",
    "    num_windows_train = int(num_windows*train_portion)\n",
    "    num_windows_val   = int(num_windows*val_portion)\n",
    "    num_windows_test  = num_windows - num_windows_train - num_windows_val\n",
    "    \n",
    "    windows = sliding_windows_per_class[class_id]\n",
    "    x_train, x_val, x_test = np.split(windows, [num_windows_train, num_windows_train + num_windows_val], axis = 0)\n",
    "    y_train, y_val, y_test = np.ones(num_windows_train)*class_id, np.ones(num_windows_val)*class_id, np.ones(num_windows_test)*class_id\n",
    "    \n",
    "    X_train.append(x_train)\n",
    "    Y_train.append(y_train)\n",
    "    \n",
    "    X_val.append(x_val)\n",
    "    Y_val.append(y_val)\n",
    "    \n",
    "    X_test.append(x_test)\n",
    "    Y_test.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7d26f28-faf4-4e27-8ce4-89b94a56207e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenating into a single array\n",
    "X_train = np.concatenate(X_train, axis = 0)\n",
    "Y_train = np.concatenate(Y_train, axis = 0)\n",
    "\n",
    "X_val = np.concatenate(X_val, axis = 0)\n",
    "Y_val = np.concatenate(Y_val, axis = 0)\n",
    "\n",
    "X_test = np.concatenate(X_test, axis = 0)\n",
    "Y_test = np.concatenate(Y_test, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a65a58-8df1-4ba0-89a2-8ba0b1b130ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 50, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4b50b8-19cf-4319-a588-c7a14cc2ef20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data normalization. We obtain the mean and std on the training set\n",
    "data_mean = np.mean(X_train, axis = 0)\n",
    "data_std  = np.std(X_train, axis = 0)\n",
    "\n",
    "# We normalize the sets using the mean and std found above\n",
    "X_train = (X_train - data_mean)/data_std\n",
    "X_val   = (X_val - data_mean)/data_std\n",
    "X_test  = (X_test - data_mean)/data_std\n",
    "\n",
    "# Now we shuffle the training data\n",
    "indices = np.arange(0, X_train.shape[0])\n",
    "random.shuffle(indices)\n",
    "X_train = X_train[indices, ...]\n",
    "Y_train = Y_train[indices, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d69e1ff-9545-4df9-85ca-311b5d951452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the X_train tensor:\n",
      "(44, 50, 2)\n",
      "New shape of the X_train tensor:\n",
      "(44, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the X_train tensor:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "# Note that we have a 3D tensor\n",
    "# The first dimension is the number of sliding windows\n",
    "# The second dimension is the number of time steps in each sliding window\n",
    "# The third dimension is the number of channels\n",
    "\n",
    "# We will transform this 3D tensor into a 2D tensor (matrix) because, for the neural network, we need a 2D tensor (num_of_sliding_windows, num_of_features)\n",
    "X_train_flat = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "X_val_flat = np.reshape(X_val, (X_val.shape[0], X_val.shape[1]*X_val.shape[2]))\n",
    "X_test_flat = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "print(\"New shape of the X_train tensor:\")\n",
    "print(X_train_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3fb7ebb-658f-423c-a89d-f8e623f28a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation accuracy for the MLP classifier: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# We create a classifier. Let's suppose we opt for 3 hidden layers\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "clf_mlp = MLPClassifier(hidden_layer_sizes=(128, 128, 128), max_iter=5000, learning_rate_init = 0.0001, activation = 'relu', solver = 'adam')\n",
    "clf_mlp.fit(X_train_flat, Y_train)\n",
    "\n",
    "val_accuracy = clf_mlp.score(X_val_flat, Y_val)*100\n",
    "print(f\"The validation accuracy for the MLP classifier: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9ea846e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mattia\\miniconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mattia\\miniconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\mattia\\miniconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mattia\\miniconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ff3e1-2dca-4360-9daa-7ce01314e9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, cnn_filters, lstm_units, num_classes):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, cnn_filters[0], kernel_size=(2,2), stride=(1,1), padding='same') # 1 input,\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,1)) # Pooling try to reduce the feature dimensions, from 2 features select 1\n",
    "\n",
    "        self.conv2 = nn.Conv2d(cnn_filters[0], cnn_filters[1], kernel_size=(2,2), stride=(1,1), padding='same')\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,1))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(cnn_filters[1], cnn_filters[2], kernel_size=(2,2), stride=(1,1), padding='same')\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2,1))\n",
    "\n",
    "        self.lstm_input_size = 6 * cnn_filters[2]\n",
    "        self.lstm = nn.LSTM(self.lstm_input_size, lstm_units, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(lstm_units, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input (32, 1, 50, 6)\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        # x (32, 16, 25, 6)\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        # x (32 ,32, 12, 6)\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        # x (32, 64, 6, 6)\n",
    "\n",
    "        # Reshape for LSTM\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch, height, width, channels)\n",
    "        # x (32, 6, 64, 6)\n",
    "        x = x.contiguous().view(x.size(0), 6, -1)  # (batch, 6, 6 * cnn_filters[2])\n",
    "        # x (32, 6, 384)\n",
    "        _, (h_n, _) = self.lstm(x)  # Get the last hidden state from LSTM\n",
    "        # h_n (1, 32, 64)\n",
    "        h_n = h_n.squeeze(0)  # Remove the extra dimension from LSTM output\n",
    "        # h_n (32, 64)\n",
    "        x = self.fc(h_n)\n",
    "        # x (32, 5)\n",
    "        x = self.softmax(x)\n",
    "        # x (32, 5)\n",
    "        return x  # output probability of 5 classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b909b-60b7-4330-952d-f229de0f124b",
   "metadata": {},
   "source": [
    "What is one hot label? digit corresponding to the label\n",
    "4 - [0 0 0 0 1]\n",
    "2 - [0 0 1 0 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0388cebf-413f-432e-a8b2-b6e36f35cf2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([44, 1, 50, 2])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Convolution.cpp:1037.)\n",
      "  return F.conv2d(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 384, got 128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m X_batch, Y_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39mto(device), Y_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 46\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, Y_batch)\n\u001b[0;32m     48\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[11], line 40\u001b[0m, in \u001b[0;36mCNN_LSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch, 6, 6 * cnn_filters[2])\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# x (32, 6, 384)\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m _, (h_n, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get the last hidden state from LSTM\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# h_n (1, 32, 64)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m h_n \u001b[38;5;241m=\u001b[39m h_n\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Remove the extra dimension from LSTM output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1101\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     c_zeros \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m   1094\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m*\u001b[39m num_directions,\n\u001b[0;32m   1095\u001b[0m         max_batch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m   1099\u001b[0m     )\n\u001b[0;32m   1100\u001b[0m     hx \u001b[38;5;241m=\u001b[39m (h_zeros, c_zeros)\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_batched:\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1002\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_forward_args\u001b[39m(\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    999\u001b[0m     hidden: Tuple[Tensor, Tensor],  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m     batch_sizes: Optional[Tensor],\n\u001b[0;32m   1001\u001b[0m ):\n\u001b[1;32m-> 1002\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[0;32m   1004\u001b[0m         hidden[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   1005\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1007\u001b[0m     )\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(\n\u001b[0;32m   1009\u001b[0m         hidden[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1012\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mattia\\miniconda3\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:314\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 384, got 128"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "epochs = 25\n",
    "batch_size = 32  # Change this based on your dataset size\n",
    "\n",
    "# Convert data to PyTorch tensors and add channel dimension\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)  # Shape: (batch, 1, 50, 6), unsqueeze is a function of Pytorch that adds a dimension to the tensor\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)  # Labels\n",
    "print(X_train_tensor.shape)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).unsqueeze(1)\n",
    "Y_val_tensor = torch.tensor(Y_val, dtype=torch.long)\n",
    "\n",
    "# One-hot encoding for labels\n",
    "Y_train_one_hot = F.one_hot(Y_train_tensor, num_classes=num_classes).float()\n",
    "Y_val_one_hot = F.one_hot(Y_val_tensor, num_classes=num_classes).float()\n",
    "print(Y_train_one_hot[0])\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_one_hot)\n",
    "val_dataset = TensorDataset(X_val_tensor, Y_val_one_hot)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) # Shuffle the data every epoch, only required in training loader\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN_LSTM([16, 32, 64], 64, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == Y_batch.argmax(1)).sum().item()\n",
    "        total += Y_batch.size(0)\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, Y_batch)\n",
    "            val_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == Y_batch.argmax(1)).sum().item()\n",
    "            total += Y_batch.size(0)\n",
    "\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a6ff4-6738-459f-8751-4d05f924a618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
